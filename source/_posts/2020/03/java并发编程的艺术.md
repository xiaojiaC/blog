---
title: java并发编程的艺术
date: 2020-03-16 19:55:32
categories:
- [JAVA, 读书笔记]
tags:
- java
- concurrency
---

## 并发编程的挑战
### 上下文切换

上下文切换：CPU通过时间片分配算法来循环执行任务，当前任务执行一个时间片后会切换到下一个任务。但是，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再加载这个任务的状态。所以任务从保存到再加载的过程就是一次上下文切换。

<!-- more -->

{% tabs 上下文切换 %}
  <!-- tab 减少方法 -->
- 无锁并发编程
- CAS算法
- 使用最少线程
- 使用协程
  <!-- endtab -->
  <!-- tab 实践案例 -->
- 减少{% label warning@WAITTING %}线程数，因为每一次从{% label warning@WAITTING %}到{% label danger@RUNNABLE %}都会进行一次上下文的切换。
  <!-- endtab -->
  <!-- tab 分析工具 -->
`vmstat`
  <!-- endtab -->
{% endtabs %}

### 死锁

死锁：多个进程在执行过程中，因争夺同类资源且资源分配不当而造成的一种互相等待的现象，若无外力作用，它们都将永远无法继续执行，这种状态称为死锁。

{% tabs 死锁 %}
  <!-- tab 产生原因 -->
- 不可剥夺资源的竞争
> 可剥夺资源：某进程在获得该类资源时，该资源同样可以被其他进程或系统剥夺。
> 不可剥夺资源：系统把该类资源分配给某个进程时不能强制收回，只能在该进程使用完成后自动释放。
- 进程推进顺序不当
  <!-- endtab -->
  <!-- tab 必要条件 -->
- 互斥条件：一个资源每次只能被一个进程使用。
- 不剥夺条件：进程已获得的资源，在末使用完之前，不能强行剥夺。
- 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
- 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。
  <!-- endtab -->
  <!-- tab 规避方法 -->
- 避免一个线程同时获取多个锁
- 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源
- 尝试使用定时锁来替代使用内部锁机制
- 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况
- 避免对长时间的计算任务和阻塞的I/O操作加锁
  <!-- endtab -->
  <!-- tab 分析工具 -->
`jps`, `jstack $pid`
  <!-- endtab -->
{% endtabs %}

### 资源限制

硬件资源限制：可以考虑使用集群并行执行程序。
软件资源限制：可以考虑使用资源池将资源复用。


## java并发机制的底层实现原理
### 基础知识

|术语|释义|
|---|----|
| 内存屏障 | 一组处理器指令，由于实现对内存操作的顺序限制。|
| 原子操作 | 不可中断的一个或一系列操作。|
| 缓存行 | 缓存中可以分配的最小存储单位。处理器填写缓存线时会加载整个缓存线，需要使用多个主内存读周期。|
| 缓存行填充 | 当处理器识别到从主存中读取的操作数是可缓存的，处理器读取整个缓存行到适当的缓存中（L1,L2,L3或所有）。|
| 缓存命中 | 如果进行高速缓存行填充操作的内存位置仍然是下次处理器访问的内存地址，处理器从缓存中读取操作数，而不是从主存中读取。|
| 写命中 | 当处理器将操作数写回到一个内存缓存的区域时，它首先会检查这个缓存的内存地址是否在缓存行中，如果存在一个有效的缓存行，则处理器将这个操作数写回到缓存，而不是写回到内存，这个操作被称为写命中。|
| 写缺失 | 一个有效的缓存行被写入到不存在的内存区域。|
| CPU流水线 | 工作方式就像工业生产中的装配流水线，在CPU中由5~6个不同功能的电路单元组成一条指令处理流水线，然后将一条x86指令拆分为5~6步再由这些电路单元分别执行，这样就能实现一个CPU时钟周期内完成一条指令，因此提高CPU的运算速度。|
| 内存顺序冲突 | 一般由假共享引起，假共享是指多个CPU同时修改同一个缓存行的不同部分而引起其中一个CPU操作无效，当出现这个内存顺序冲突时，CPU必须清空流水线。 |

### volatile

`volatile`变量修饰的共享变量进行写操作的时候会多出一个*lock前缀的指令*，该指令在多核处理器下会引发：
1. 将当前处理器缓存行的数据回写到系统内存。
2. 这个回写内存的操作会使在其他CPU里缓存了该内存地址的数据无效。

实现原理：
> 声明了volatile的变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写回到系统内存。但是，就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作就会有问题。所以，在多处理器下，为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里。

为什么`LinkedTransferQueue`中头、尾volatile变量追加64字节能够提高并发编程的效率呢？

大部分处理器高速缓存行是64个字节宽，且不支持部分填充缓存行。使用追加到64字节的方式来填满高速缓冲区的缓存行，避免头节点和尾节点加载到同一个缓存行，使头、尾节点在修改时不会互相锁定。

是不是在使用`volatile`变量时都应该追加到64字节呢？**并非如此**，在两种场景下不应该使用这种方式：
- 缓存行非64字节宽的处理器
- 共享变量不会被频繁地写

{% note warning %}
不过这种追加字节的方式在Java 7下可能不生效，因为Java 7变得更加智慧，它会淘汰或重新排列无用字段，需要使用其他追加字节的方式。
{% endnote %}

{% note info %}
你可能想看这里: [神奇的缓存行填充](https://blog.csdn.net/aigoogle/article/details/41517213)
{% endnote %}

### synchronized

实现原理：

> JVM基于进入和退出Monitor对象来实现方法同步和代码块同步，但两者的实现细节不一样。代码块同步是使用`monitorenter`和`monitorexit`指令实现的，而方法同步是使用另外一种方式实现的，细节在JVM规范里并没有详细说明。但是，方法的同步同样可以使用这两个指令来实现。`monitorenter`指令是在编译后插入到同步代码块的开始位置，而`monitorexit`是插入到方法结束处和异常处，JVM要保证每个`monitorenter`必须有对应的`monitorexit`与之配对。任何对象都有一个monitor与之关联，当且一个monitor被持有后，它将处于锁定状态。线程执行到`monitorenter`指令时，将会尝试获取对象所对应的monitor的所有权，即尝试获得对象的锁。

`synchronized`用的锁是存在Java对象头里的。其存储结构如下示：

第一部分：
{% asset_img markword-32bit-vm.PNG %}
{% asset_img markword-64bit-vm.PNG %}

第二部分：
类型指针，即对象指向类元数据的指针，虚拟机通过这个指针来确定对象是哪个类的实例。但并不是所有虚拟机实现都需要在对象头上保持类型指针。因为有的虚拟机使用*句柄*进行对象访问定位，而不是*直接指针*访问。

第三部分：
如果对象是一个java数组，那么在对象头中还必须有一块用于记录数组长度的数据。可能是对齐填充，并不是必要存在的，也没有特别含义，仅起占位符的作用。

#### 锁

在Java SE 1.6中，锁一共有4种状态，级别从低到高依次是：**无锁状态**、**偏向锁状态**、**轻量级锁状态**和**重量级锁**状态，这几个状态会随着竞争情况逐渐升级。锁可以升级但不能降级。

{% asset_img synchonized.png %}

### 原子操作

原子操作：不可被中断的一个或一系列操作。

处理器如何实现原子操作：
- 通过总线锁保证原子性（总线上声明`lock#`信号）
- 通过缓存锁定来保证原子性（修改内部的内存地址+缓存一致性机制使*单个*缓存行无效）

Java如何实现原子操作：
- 使用循环CAS
    - ABA问题：解决方法追加版本号，可参考`AtomicStampedReference`
    - 循环时间长开销大
    - 只能保证一个共享变量的原子操作：解决方法使用锁替换或把多个共享变量合并成一个共享变量来操作，可参考`AtomicReference`
- 使用锁机制


## Java内存模型
### 基础知识

命令式编程中，线程之间的通信机制有两种：**共享内存**和**消息传递**。

从源代码到指令序列可能发生哪些重排序？
- 编译器优化的重排序：编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。
- 指令级并行的重排序：如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。
> 如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性。
- 内存系统的重排序：由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。

{% asset_img code-to-instruction-reorder.PNG 源代码到指令序列的重排序 %}

Java线程之间的通信由*Java内存模型*控制，JMM决定一个线程对共享变量的写入何时对另一个线程可见。确保在不同的编译器和不同的处理器平台之上，为程序员提供一致的内存可见性保证。

对于编译器重排序，JMM的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。
对于处理器重排序，JMM的处理器重排序规则会要求Java编译器在生成指令序列时，插入特定类型的内存屏障指令，通过内存屏障指令来禁止特定类型的处理器重排序。



Java中所有**实例域**、**静态域**和**数组元素**都存储在堆内存中，堆内存在线程之间共享。





----
* [Synchronization](https://wiki.openjdk.java.net/display/HotSpot/Synchronization)
* [Java Synchronised机制](https://blog.dreamtobe.cn/2015/11/13/java_synchronized/)